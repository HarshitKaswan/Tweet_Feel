{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8704f630-8ace-409f-867e-4eb12e0b7477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load pre-trained model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/HP/Downloads/Complete Model-20231209T172305Z-001/Complete Model/model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load pre-trained model\n",
    "model_path = 'C:/Users/HP/Downloads/Complete Model-20231209T172305Z-001/Complete Model/model.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load tokenizer\n",
    "with open(\"C:/Users/HP/Downloads/Complete Model-20231209T172305Z-001/Complete Model/tokenizer.pkl\", 'rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "SEQUENCE_LENGTH = 300\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.8)\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "\n",
    "def predict_sentiment(text, model, tokenizer):\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "\n",
    "    # Predict\n",
    "    score = model.predict(x_test)[0]\n",
    "\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=True)\n",
    "\n",
    "    return label, float(score)\n",
    "\n",
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            return NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            return POSITIVE\n",
    "        else:\n",
    "            return NEUTRAL\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE\n",
    "\n",
    "def draw_gauge(sentiment_score, max_value, title=\"Meter\"):\n",
    "    label = decode_sentiment(sentiment_score)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=sentiment_score,\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "        title={'text': title},\n",
    "        gauge=dict(\n",
    "            axis=dict(range=[0, 1]),\n",
    "            bar=dict(color=\"blue\"),\n",
    "            steps=[\n",
    "                dict(range=[0, SENTIMENT_THRESHOLDS[0]], color=\"red\"),\n",
    "                dict(range=[SENTIMENT_THRESHOLDS[0], SENTIMENT_THRESHOLDS[1]], color=\"yellow\"),\n",
    "                dict(range=[SENTIMENT_THRESHOLDS[1], 1], color=\"green\")\n",
    "            ]\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Add text label below the graph\n",
    "    fig.add_annotation(\n",
    "        go.layout.Annotation(\n",
    "            text=label,\n",
    "            x=0.5,\n",
    "            y=-0.2,\n",
    "            showarrow=False,\n",
    "            font=dict(size=16),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Set the background color to white\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Example usage\n",
    "# text_to_analyze = \"This is a great product!\"\n",
    "# label, score = predict_sentiment(text_to_analyze, model, tokenizer)\n",
    "# draw_gauge(score, 1, title=\"Sentiment Score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6cde3d0-9494-4c69-9677-ce4c679fd434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load pre-trained model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/HP/Downloads/Complete Model-20231209T172305Z-001/Complete Model/model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(model_path)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/HP/Downloads/Complete Model-20231209T172305Z-001/Complete Model/tokenizer.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model\n",
    "model_path = 'C:/Users/HP/Downloads/Complete Model-20231209T172305Z-001/Complete Model/model.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load tokenizer\n",
    "with open(\"C:/Users/HP/Downloads/Complete Model-20231209T172305Z-001/Complete Model/tokenizer.pkl\", 'rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "SEQUENCE_LENGTH = 300\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.8)\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "\n",
    "    # Predict\n",
    "    score = model.predict(x_test)[0]\n",
    "\n",
    "    return score\n",
    "\n",
    "def decode_sentiment(score):\n",
    "    if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "        return NEGATIVE\n",
    "    elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return NEUTRAL\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    score = predict_sentiment(text)\n",
    "    label = decode_sentiment(score)\n",
    "\n",
    "    # Convert score to float for Gradio Gauge\n",
    "    score_value = float(score)\n",
    "\n",
    "    # Create gauge chart\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=score_value,\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "        title={'text': \"Sentiment Score\"},\n",
    "        gauge=dict(\n",
    "            axis=dict(range=[0, 1]),\n",
    "            bar=dict(color=\"blue\"),\n",
    "            steps=[\n",
    "                dict(range=[0, SENTIMENT_THRESHOLDS[0]], color=\"red\"),\n",
    "                dict(range=[SENTIMENT_THRESHOLDS[0], SENTIMENT_THRESHOLDS[1]], color=\"yellow\"),\n",
    "                dict(range=[SENTIMENT_THRESHOLDS[1], 1], color=\"green\")\n",
    "            ]\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Add text label below the graph\n",
    "    fig.add_annotation(\n",
    "        go.layout.Annotation(\n",
    "            text=label,\n",
    "            x=0.5,\n",
    "            y=-0.2,\n",
    "            showarrow=False,\n",
    "            font=dict(size=16),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Set the background color to white\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    # Create text element to display score and label\n",
    "    text_output = f\"Score: {score_value:.4f}\\nLabel: {label}\"\n",
    "\n",
    "    return fig, text_output\n",
    "\n",
    "iface = gr.Interface(fn=sentiment_analysis, inputs=\"text\", outputs=[\"plot\", \"text\"],title=\"Sentiment Analysis\", description=\"Enter a text to analyze its sentiment.\")\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6ed484-569d-4851-ae30-e9845cbd710d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "[0.03064266]\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "text_to_predict = \"This restaurant has terrible service; I won't be coming back.\"\n",
    "prediction_result = predict_sentiment(text_to_predict, model, tokenizer)\n",
    "print(prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a56c79-4ea1-4d69-9a0a-90af10f06233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
